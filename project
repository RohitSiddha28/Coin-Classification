1

from google.colab import drive
drive.mount('/content/drive')

data_path = "/content/drive/MyDrive/dl4cv-coin-classification/kaggle"

!ls "/content/drive/MyDrive/dl4cv-coin-classification/kaggle"

import pandas as pd

test_df = pd.read_csv(f"{data_path}/train.csv")
test_df.head()

import os
from PIL import Image
import matplotlib.pyplot as plt

# Path to the test images folder
test_folder = f"{data_path}/test"

# List all image files in the test folder
image_files = os.listdir(test_folder)

# Pick the first one (or use random.choice for random)
img_file = image_files[0]  # or use image_files[n] for nth image
img_path = os.path.join(test_folder, img_file)

# Open and display the image
img = Image.open(img_path)
plt.imshow(img)
plt.title(f"Test Image: {img_file}")
plt.axis('off')
plt.show()

import pandas as pd

data_path = "/content/drive/MyDrive/dl4cv-coin-classification/kaggle"
train_df = pd.read_csv(f"{data_path}/train.csv")
pd.set_option('display.max_rows', None)

# Count samples per class
class_counts = train_df['Class'].value_counts()

# Display top 10 classes with most samples
#print(class_counts.head(10))

# Or view entire distribution
print(class_counts)

# Print total number of unique classes
print(f"\nTotal unique classes: {len(class_counts)}")

import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
import os

# ‚úÖ Path to your dataset folder in Google Drive
data_path = "/content/drive/MyDrive/dl4cv-coin-classification/kaggle"
train_csv_path = os.path.join(data_path, "train.csv")
train_folder = os.path.join(data_path, "train")

# ‚úÖ Load the CSV with correct column names
train_df = pd.read_csv(train_csv_path)

# ‚úÖ Group by 'Class' and take one sample (first) for each
sample_df = train_df.groupby("Class").first().reset_index()

# ‚úÖ Total classes (should be 315)
print("Total unique classes:", len(sample_df))

# ‚úÖ Plotting function
def plot_samples(df, images_per_row=6, rows=6, start_idx=0):
    images_per_page = images_per_row * rows
    total_images = len(df)
    end_idx = min(start_idx + images_per_page, total_images)
    num_to_plot = end_idx - start_idx

    fig, axes = plt.subplots(rows, images_per_row, figsize=(18, 18))
    axes = axes.flatten()

    for i in range(num_to_plot):
        img_id = df.iloc[start_idx + i]['Id']
        class_name = df.iloc[start_idx + i]['Class']
        img_path = os.path.join(train_folder, f"{img_id}.jpg")

        try:
            img = Image.open(img_path)
            axes[i].imshow(img)
            axes[i].set_title(class_name[:30], fontsize=8)  # Limit title length
            axes[i].axis('off')
        except Exception as e:
            axes[i].set_title("Error")
            axes[i].axis('off')

    # Hide unused subplots
    for j in range(num_to_plot, len(axes)):
        axes[j].axis('off')

    plt.tight_layout()
    plt.show()

# ‚úÖ Show all 315 classes in pages (36 per page)
for i in range(0, len(sample_df), 36):
    print(f"Showing classes {i+1} to {min(i+36, len(sample_df))}")
    plot_samples(sample_df, images_per_row=6, rows=6, start_idx=i)


from PIL import Image
import os
from collections import Counter
import pandas as pd

# Folder where training images are stored
train_folder = "/content/drive/MyDrive/dl4cv-coin-classification/kaggle/train"

# List all image files
image_files = [f for f in os.listdir(train_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

# Initialize counters
size_counter = Counter()
format_counter = Counter()
corrupted_files = []

# Loop through all images
for img_file in image_files:
    img_path = os.path.join(train_folder, img_file)
    try:
        with Image.open(img_path) as img:
            size_counter[img.size] += 1           # (width, height)
            format_counter[img.format] += 1       # JPG, PNG, etc.
    except Exception as e:
        corrupted_files.append(img_file)

# üìè Display common image sizes
print("\n‚úÖ Image Sizes (Width √ó Height):")
for size, count in size_counter.most_common():
    print(f"{size[0]}√ó{size[1]}  --> {count} images")

# üìÇ Display file formats
print("\n‚úÖ File Formats:")
for fmt, count in format_counter.items():
    print(f"{fmt} --> {count} images")

# ‚ùå Check for corrupted images
if corrupted_files:
    print(f"\n‚ö†Ô∏è Corrupted or unreadable images: {len(corrupted_files)}")
    print(corrupted_files[:5])  # show first few
else:
    print("\n‚úÖ No corrupted images found.")

from PIL import Image
import os

# ‚úÖ Your training image folder
train_folder = "/content/drive/MyDrive/dl4cv-coin-classification/kaggle/train"

# ‚úÖ Define allowed image formats
allowed_exts = ['.jpg', '.webp', '.png']

# üìù Stats
deleted_corrupted = []
deleted_format = []

# ‚úÖ Loop through all images
for img_file in os.listdir(train_folder):
    img_path = os.path.join(train_folder, img_file)
    ext = os.path.splitext(img_file)[-1].lower()

    # Remove unsupported formats (like .gif, .webp)
    if ext not in allowed_exts:
        os.remove(img_path)
        deleted_format.append(img_file)
        print(f"üßπ Removed unsupported format: {img_file}")
        continue

    # Try to open the image to catch corrupted files
    try:
        with Image.open(img_path) as img:
            img.verify()  # check if corrupted
    except Exception:
        os.remove(img_path)
        deleted_corrupted.append(img_file)
        print(f"‚ùå Removed corrupted file: {img_file}")

# ‚úÖ Summary
print("\n‚úÖ Cleanup complete!")
print(f"üßπ Non-standard format images removed: {len(deleted_format)}")
print(f"‚ùå Corrupted images removed: {len(deleted_corrupted)}")

from PIL import Image
import os
from collections import Counter
import pandas as pd

# Folder where training images are stored
train_folder = "/content/drive/MyDrive/dl4cv-coin-classification/kaggle/train"

# List all image files
image_files = [f for f in os.listdir(train_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

# Initialize counters
size_counter = Counter()
format_counter = Counter()
corrupted_files = []

# Loop through all images
for img_file in image_files:
    img_path = os.path.join(train_folder, img_file)
    try:
        with Image.open(img_path) as img:
            size_counter[img.size] += 1           # (width, height)
            format_counter[img.format] += 1       # JPG, PNG, etc.
    except Exception as e:
        corrupted_files.append(img_file)

# üìè Display common image sizes
print("\n‚úÖ Image Sizes (Width √ó Height):")
for size, count in size_counter.most_common():
    print(f"{size[0]}√ó{size[1]}  --> {count} images")

# üìÇ Display file formats
print("\n‚úÖ File Formats:")
for fmt, count in format_counter.items():
    print(f"{fmt} --> {count} images")

# ‚ùå Check for corrupted images
if corrupted_files:
    print(f"\n‚ö†Ô∏è Corrupted or unreadable images: {len(corrupted_files)}")
    print(corrupted_files[:5])  # show first few
else:
    print("\n‚úÖ No corrupted images found.")

2

from PIL import Image
import os

# ‚úÖ Path to your training image folder
train_folder = "/content/drive/MyDrive/dl4cv-coin-classification/kaggle/train"

# ‚úÖ Resize settings
target_size = (128, 128)  # Change to (256, 256) if needed

# üßº Resize in-place
resized_count = 0

for img_file in os.listdir(train_folder):
    img_path = os.path.join(train_folder, img_file)
    try:
        with Image.open(img_path) as img:
            img = img.convert("RGB")  # Ensure 3 channels
            img = img.resize(target_size)
            img.save(img_path)
            resized_count += 1
    except Exception as e:
        print(f"‚ùå Error resizing: {img_file} ‚Äî {e}")

print(f"\n‚úÖ Resized {resized_count} images to {target_size[0]}√ó{target_size[1]}")


import tensorflow as tf
import os

# Folder containing images
train_folder = "/content/drive/MyDrive/dl4cv-coin-classification/kaggle/train"

# Get list of image file paths (jpg/jpeg/png)
image_paths = [
    os.path.join(train_folder, f)
    for f in os.listdir(train_folder)
    if f.lower().endswith((".jpg", ".jpeg", ".png"))
]

# Load and normalize each image
normalized_images = []

for path in image_paths:
    try:
        image = tf.io.read_file(path)
        image = tf.image.decode_image(image, channels=3)  # Handle jpg/png
        image = tf.image.convert_image_dtype(image, tf.float32)  # Normalize to [0, 1]
        normalized_images.append(image)
    except Exception as e:
        print(f"‚ùå Could not process {path}: {e}")

print(f"‚úÖ Total normalized images: {len(normalized_images)}")

import pandas as pd
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical

# Load your train.csv
df = pd.read_csv("/content/drive/MyDrive/dl4cv-coin-classification/kaggle/train.csv")

# Step 1: Convert string labels to integers
le = LabelEncoder()
df['label_encoded'] = le.fit_transform(df['Class'])

# Step 2: Convert integer labels to one-hot encoded
one_hot_labels = to_categorical(df['label_encoded'])

# one_hot_labels is a NumPy array of shape (num_samples, num_classes)
print(f"‚úÖ One-hot shape: {one_hot_labels.shape}")
print(f"üß™ Sample:\n{one_hot_labels[:3]}")


import pandas as pd
from sklearn.model_selection import train_test_split

# Load your train.csv
df = pd.read_csv("/content/drive/MyDrive/dl4cv-coin-classification/kaggle/train.csv")

# Label encoding for stratification
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['label_encoded'] = le.fit_transform(df['Class'])

# Step 1: Train (70%) and temp (30%)
train_df, temp_df = train_test_split(
    df,
    test_size=0.30,
    stratify=df['label_encoded'],
    random_state=42
)

# Step 2: Split temp into val (15%) and test (15%)
val_df, test_df = train_test_split(
    temp_df,
    test_size=0.5,  # 50% of 30% = 15%
    stratify=temp_df['label_encoded'],
    random_state=42
)

# ‚úÖ Final sizes
print(f"Train size: {len(train_df)}")
print(f"Validation size: {len(val_df)}")
print(f"Test size: {len(test_df)}")


3

import tensorflow as tf
from tensorflow.keras import layers, models

# Number of output classes
num_classes = 315

# Image shape (after resize)
input_shape = (128, 128, 3)

# Build the CNN
def create_cnn():
    inputs = tf.keras.Input(shape=input_shape)

    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
    x = layers.MaxPooling2D((2, 2))(x)

    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = layers.MaxPooling2D((2, 2))(x)

    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = layers.MaxPooling2D((2, 2))(x)

    x = layers.Flatten()(x)
    x = layers.Dense(256, activation='relu')(x)
    x = layers.Dropout(0.5)(x)

    outputs = layers.Dense(num_classes, activation='softmax')(x)

    model = models.Model(inputs, outputs)
    return model

# Create the model
model = create_cnn()

# Summary
model.summary()


from tensorflow.keras.utils import plot_model

plot_model(
    model,
    to_file='cnn_diagram.png',
    show_shapes=True,
    show_layer_names=True,
    dpi=96
)

from tensorflow.keras.utils import plot_model

plot_model(
    model,
    to_file="cnn_model.png",
    show_shapes=True,
    show_layer_names=True,
    dpi=120
)

# Filter dataframes to include only images that exist in the training folder
train_folder = "/content/drive/MyDrive/dl4cv-coin-classification/kaggle/train"
image_files_on_disk = set(os.listdir(train_folder))

train_df_filtered = train_df[train_df['Id'].apply(lambda x: f"{x}.jpg" in image_files_on_disk)]
val_df_filtered = val_df[val_df['Id'].apply(lambda x: f"{x}.jpg" in image_files_on_disk)]
test_df_filtered = test_df[test_df['Id'].apply(lambda x: f"{x}.jpg" in image_files_on_disk)]

print(f"Original train size: {len(train_df)}, Filtered train size: {len(train_df_filtered)}")
print(f"Original validation size: {len(val_df)}, Filtered validation size: {len(val_df_filtered)}")
print(f"Original test size: {len(test_df)}, Filtered test size: {len(test_df_filtered)}")

# Update train_df, val_df, and test_df to use the filtered dataframes
train_df = train_df_filtered
val_df = val_df_filtered
test_df = test_df_filtered

import tensorflow as tf
import os

# Function to load and preprocess images
def load_and_preprocess_image(image_path, label):
    img = tf.io.read_file(image_path)
    img = tf.image.decode_jpeg(img, channels=3)  # Assuming JPEG format based on file formats analysis
    img = tf.image.convert_image_dtype(img, tf.float32) # Normalize to [0, 1]
    img = tf.image.resize(img, (128, 128)) # Resize to target size
    return img, label

# Create TensorFlow Datasets
train_image_paths = [os.path.join(train_folder, f"{id}.jpg") for id in train_df['Id']]
train_labels = train_df['label_encoded']

val_image_paths = [os.path.join(train_folder, f"{id}.jpg") for id in val_df['Id']]
val_labels = val_df['label_encoded']

# Convert integer labels to one-hot encoded
from tensorflow.keras.utils import to_categorical
train_one_hot_labels = to_categorical(train_labels, num_classes=num_classes)
val_one_hot_labels = to_categorical(val_labels, num_classes=num_classes)


train_ds = tf.data.Dataset.from_tensor_slices((train_image_paths, train_one_hot_labels))
val_ds = tf.data.Dataset.from_tensor_slices((val_image_paths, val_one_hot_labels))

# Map the loading and preprocessing function to the datasets
train_ds = train_ds.map(load_and_preprocess_image).batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)
val_ds = val_ds.map(load_and_preprocess_image).batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)

print("‚úÖ TensorFlow Datasets created.")

# Rebuild the same CNN architecture
model = create_cnn()

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

checkpoint_path = "/content/drive/MyDrive/best_coin_model.h5"

early_stop = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)

checkpoint = ModelCheckpoint(
    filepath=checkpoint_path,
    monitor='val_accuracy',
    save_best_only=True,
    verbose=1
)

# Train again from scratch
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=30,
    callbacks=[early_stop, checkpoint],
    verbose=1
)

import matplotlib.pyplot as plt

# Extract training history
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(acc) + 1)

# üìà Accuracy Plot
plt.figure(figsize=(14, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, acc, 'bo-', label='Training Accuracy')
plt.plot(epochs, val_acc, 'ro-', label='Validation Accuracy')
plt.title('Training & Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid()

# üìâ Loss Plot
plt.subplot(1, 2, 2)
plt.plot(epochs, loss, 'bo-', label='Training Loss')
plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')
plt.title('Training & Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid()

plt.tight_layout()
plt.show()


5

import tensorflow as tf
import os

# Function to load and preprocess images
def load_and_preprocess_image(image_path, label):
    img = tf.io.read_file(image_path)
    img = tf.image.decode_jpeg(img, channels=3)  # Assuming JPEG format based on file formats analysis
    img = tf.image.convert_image_dtype(img, tf.float32) # Normalize to [0, 1]
    img = tf.image.resize(img, (128, 128)) # Resize to target size
    return img, label

# Function to create a TensorFlow dataset from a dataframe
def create_dataset(df, train_folder, num_classes, shuffle=True):
    image_paths = [os.path.join(train_folder, f"{id}.jpg") for id in df['Id']]
    labels = df['label_encoded']

    # Convert integer labels to one-hot encoded
    from tensorflow.keras.utils import to_categorical
    one_hot_labels = to_categorical(labels, num_classes=num_classes)

    ds = tf.data.Dataset.from_tensor_slices((image_paths, one_hot_labels))

    if shuffle:
        ds = ds.shuffle(buffer_size=1000) # Adjust buffer size as needed

    ds = ds.map(load_and_preprocess_image).batch(32).prefetch(buffer_size=tf.data.AUTOTUNE)
    return ds

# Create TensorFlow Datasets
train_folder = "/content/drive/MyDrive/dl4cv-coin-classification/kaggle/train"
train_ds = create_dataset(train_df, train_folder, num_classes)
val_ds = create_dataset(val_df, train_folder, num_classes, shuffle=False)
test_ds = create_dataset(test_df, train_folder, num_classes, shuffle=False)

print("‚úÖ TensorFlow Datasets created.")

y_pred_probs = model.predict(test_ds)
y_pred = tf.argmax(y_pred_probs, axis=1).numpy()
y_true = test_df['label_encoded'].values

import numpy as np

used_classes = np.unique(y_true)
print(f"‚úÖ Used label indices: {len(used_classes)} classes found in test set")

# Only keep names of classes that appear in y_true
filtered_class_names = le.classes_[used_classes]

from sklearn.metrics import classification_report

report = classification_report(
    y_true,
    y_pred,
    labels=used_classes,
    target_names=filtered_class_names,
    zero_division=0
)

print(report)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Step 1: Compute confusion matrix
cm = confusion_matrix(y_true, y_pred, labels=used_classes)

# Step 2: Normalize (optional)
cm_norm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]

# Step 3: Plot
plt.figure(figsize=(18, 18))
sns.heatmap(cm_norm,
            xticklabels=filtered_class_names,
            yticklabels=filtered_class_names,
            annot=False, fmt=".2f", cmap="Blues")

plt.title("Normalized Confusion Matrix", fontsize=16)
plt.xlabel("Predicted Label", fontsize=14)
plt.ylabel("True Label", fontsize=14)
plt.tight_layout()
plt.show()

6

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(acc) + 1)

plt.figure(figsize=(14, 5))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(epochs, acc, 'bo-', label='Train Accuracy')
plt.plot(epochs, val_acc, 'ro-', label='Val Accuracy')
plt.title('Training vs Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(epochs, loss, 'bo-', label='Train Loss')
plt.plot(epochs, val_loss, 'ro-', label='Val Loss')
plt.title('Training vs Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Create readable labels using LabelEncoder
true_labels = le.inverse_transform(y_true)
pred_labels = le.inverse_transform(y_pred)

# Combine into a DataFrame
import pandas as pd

results_df = pd.DataFrame({
    "Image ID": test_df["Id"].values,
    "True Class": true_labels,
    "Predicted Class": pred_labels,
    "Correct": y_true == y_pred
})

# Display all predictions
pd.set_option('display.max_rows', None)  # Show all rows
print(results_df)

correct_count = results_df["Correct"].sum()
total_count = len(results_df)
incorrect_count = total_count - correct_count

# For plotting
counts = [correct_count, incorrect_count]
labels = ['Correct', 'Incorrect']
percentages = [count / total_count * 100 for count in counts]

import matplotlib.pyplot as plt

plt.figure(figsize=(6, 6))
plt.pie(counts, labels=labels, autopct='%1.1f%%', colors=['green', 'red'], startangle=90)
plt.title('‚úÖ Prediction Accuracy Distribution')
plt.axis('equal')  # Equal aspect ratio ensures the pie is circular
plt.show()

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import cv2
from tensorflow.keras.models import Model

# Function to generate Grad-CAM
def get_gradcam_heatmap(model, image, class_index, last_conv_layer_name):
    grad_model = Model(
        inputs=model.inputs,
        outputs=[model.get_layer(last_conv_layer_name).output, model.output]
    )

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(tf.expand_dims(image, axis=0))
        loss = predictions[:, class_index]

    grads = tape.gradient(loss, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs[0]
    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)
    heatmap = np.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()

# Show Grad-CAM on a test image
def show_gradcam(image_path, model, true_label, last_conv_layer_name='conv2d_2'):
    img = tf.io.read_file(image_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.convert_image_dtype(img, tf.float32)
    img = tf.image.resize(img, (128, 128))

    prediction = model.predict(tf.expand_dims(img, axis=0))
    pred_index = tf.argmax(prediction[0]).numpy()
    pred_class = le.inverse_transform([pred_index])[0]

    heatmap = get_gradcam_heatmap(model, img, pred_index, last_conv_layer_name)

    # Overlay the heatmap
    img_np = img.numpy()
    heatmap_resized = cv2.resize(heatmap, (img_np.shape[1], img_np.shape[0]))
    heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)
    heatmap_color = heatmap_color / 255.0
    overlay = heatmap_color * 0.4 + img_np

    plt.figure(figsize=(10, 4))
    plt.subplot(1, 3, 1)
    plt.imshow(img_np)
    plt.title(f"True: {true_label}")

    plt.subplot(1, 3, 2)
    plt.imshow(heatmap_resized, cmap='jet')
    plt.title("Grad-CAM Heatmap")

    plt.subplot(1, 3, 3)
    plt.imshow(overlay)
    plt.title(f"Predicted: {pred_class}")
    plt.tight_layout()
    plt.show()


# Identify first incorrect prediction
incorrect_row = results_df[results_df["Correct"] == False].iloc[0]
img_id = incorrect_row["Image ID"]
true_class = incorrect_row["True Class"]

# Build image path
img_path = os.path.join(train_folder, f"{img_id}.jpg")

# Show Grad-CAM for this image
show_gradcam(
    image_path=img_path,
    model=model,
    true_label=true_class,
    last_conv_layer_name="conv2d_11"  # Your last Conv2D layer
)


def load_and_preprocess_image(image_path, label, augment=False):
    img = tf.io.read_file(image_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.convert_image_dtype(img, tf.float32)  # Normalize to [0, 1]
    img = tf.image.resize(img, (128, 128))

    if augment:
        img = tf.image.random_flip_left_right(img)
        img = tf.image.random_flip_up_down(img)
        img = tf.image.random_brightness(img, max_delta=0.2)
        img = tf.image.rot90(img, k=tf.random.uniform([], minval=0, maxval=4, dtype=tf.int32))

    return img, label


def create_dataset(df, train_folder, num_classes, shuffle=True, augment=False):
    image_paths = [os.path.join(train_folder, f"{id}.jpg") for id in df['Id']]
    labels = df['label_encoded']
    one_hot_labels = to_categorical(labels, num_classes=num_classes)

    ds = tf.data.Dataset.from_tensor_slices((image_paths, one_hot_labels))

    if shuffle:
        ds = ds.shuffle(buffer_size=1000)

    # üëá Pass augment flag here
    ds = ds.map(lambda x, y: load_and_preprocess_image(x, y, augment=augment),
                num_parallel_calls=tf.data.AUTOTUNE)

    ds = ds.batch(32).prefetch(tf.data.AUTOTUNE)
    return ds


train_ds = create_dataset(train_df, train_folder, num_classes, shuffle=True, augment=True)
val_ds = create_dataset(val_df, train_folder, num_classes, shuffle=False, augment=False)
test_ds = create_dataset(test_df, train_folder, num_classes, shuffle=False, augment=False)
